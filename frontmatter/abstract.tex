
We present a \emph{divide–et–impera} extension of the (Quantics) Tensor Cross Interpolation algorithm \cite{Fernandez2024} that adaptively partitions a high-dimensional tensor into a collection of low-rank TT \emph{patches}. Each patch is compressed with an explicit bond-dimension cap \(\chi_{\text{patch}}\), that triggers finer partitioning of the configuration space wherever the input tensor has more interesting features (higher local rank). The local cap \(\chi_{\text{patch}}\) not only reduces the memory footprint of tensor-train representation of functions with sharply local features, but also tames the \(\mathcal{O}(\chi^{4})\) cost of MPO-MPO contractions by decomposing the global product into many rank-\(\le\chi_{\text{patch}}\) sub-contractions; in this context, the choice of MPO patching scheme is essential, as it can markedly enhances—or, if poorly chosen, limits—the overall efficiency of patched contractions.

We derive closed-form bounds that relate \(\chi_{\text{patch}}\) and the patch count \(N_{\text{patch}}\) to the memory and run-time advantage over a monolithic TCI or MPO contraction, and identify an ``over-patching'' regime that arises if the cap is chosen too small.  The theoretical estimates are validated by comprehensive benchmarks and the advantage is tested on three notorious bottlenecks of many-body physics related to the Hubbard model: (i) the approximaton of two-dimensional Matsubara Green's function,  
(ii) the computation of the bare susceptibility \(\chi_{0}(\mathbf q,i\omega)\)  
(\emph{bubble} diagram), and (iii) vertex contractions entering the Bethe-Salpeter equation for the single-impurity Anderson model. In all cases the patched strategy yields significant memory savings together with speed-ups of nearly an order of magnitude, enabling computations that remain out of practical reach for the monolithic method.
