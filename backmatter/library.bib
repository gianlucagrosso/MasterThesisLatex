@article{Fannes1992,
author={Fannes, M.
and Nachtergaele, B.
and Werner, R. F.},
title={Finitely correlated states on quantum spin chains},
journal={Communications in Mathematical Physics},
year={1992},
month={Mar},
day={01},
volume={144},
number={3},
pages={443-490},
abstract={We study a construction that yields a class of translation invariant states on quantum spin chains, characterized by the property that the correlations across any bond can be modeled on a finite-dimensional vector space. These states can be considered as generalized valence bond states, and they are dense in the set of all translation invariant states. We develop a complete theory of the ergodic decomposition of such states, including the decomposition into periodic ``N{\'e}el ordered'' states. The ergodic components have exponential decay of correlations. All states considered can be obtained as ``local functions'' of states of a special kind, so-called ``purely generated states,'' which are shown to be ground states for suitably chosen finite range VBS interactions. We show that all these generalized VBS models have a spectral gap. Our theory does not require symmetry of the state with respect to a local gauge group. In particular we illustrate our results with a one-parameter family of examples which are not isotropic except for one special case. This isotropic model coincides with the one-dimensional antiferromagnet, recently studied by Affleck, Kennedy, Lieb, and Tasaki.},
issn={1432-0916},
doi={10.1007/BF02099178},
url={https://doi.org/10.1007/BF02099178}
}



@article{PhysRevLett.69.2863,
  title = {Density matrix formulation for quantum renormalization groups},
  author = {White, Steven R.},
  journal = {Phys. Rev. Lett.},
  volume = {69},
  issue = {19},
  pages = {2863--2866},
  numpages = {0},
  year = {1992},
  month = {11},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.69.2863},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.69.2863}
}

@article{SCHOLLWOCK201196,
title = {The density-matrix renormalization group in the age of matrix product states},
journal = {Annals of Physics},
volume = {326},
number = {1},
pages = {96-192},
year = {2011},
note = {January 2011 Special Issue},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2010.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0003491610001752},
author = {Ulrich Schollwöck},
abstract = {The density-matrix renormalization group method (DMRG) has established itself over the last decade as the leading method for the simulation of the statics and dynamics of one-dimensional strongly correlated quantum lattice systems. In the further development of the method, the realization that DMRG operates on a highly interesting class of quantum states, so-called matrix product states (MPS), has allowed a much deeper understanding of the inner structure of the DMRG method, its further potential and its limitations. In this paper, I want to give a detailed exposition of current DMRG thinking in the MPS language in order to make the advisable implementation of the family of DMRG algorithms in exclusively MPS terms transparent. I then move on to discuss some directions of potentially fruitful further algorithmic development: while DMRG is a very mature method by now, I still see potential for further improvements, as exemplified by a number of recently introduced algorithms.}
}

@article{PhysRevLett.91.147902,
  title = {Efficient Classical Simulation of Slightly Entangled Quantum Computations},
  author = {Vidal, Guifr\'e},
  journal = {Phys. Rev. Lett.},
  volume = {91},
  issue = {14},
  pages = {147902},
  numpages = {4},
  year = {2003},
  month = {10},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.91.147902},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.91.147902}
}

@misc{verstraete2004renormalizationalgorithmsquantummanybody,
      title={Renormalization algorithms for Quantum-Many Body Systems in two and higher dimensions}, 
      author={F. Verstraete and J. I. Cirac},
      year={2004},
      eprint={cond-mat/0407066},
      archivePrefix={arXiv},
      primaryClass={cond-mat.str-el},
      url={https://arxiv.org/abs/cond-mat/0407066}, 
}

@misc{vonDelftTNNotes,
    author       = {von Delft, Jan},
    title        = {Lecture Notes on Tensor Networks for Many-Body Physics},
    note = {Ludwig-Maximilians University of Munich, Theoretical Solid State Physics, \href{https://www2.physik.uni-muenchen.de/lehre/vorlesungen/sose_23/tensor_networks_23/skript/index.html}{Lecture Notes (2023)}},
}

@misc{tensornetwork.org,
  author       = {Stoudemire, Miles},
  title        = {\href{https://tensornetwork.org}{tensornetwork.org}},
  url = {https://tensornetwork.org},
}

@article{Fernandez2024,
 author        = {Yuriel N\'u\~nez Fern\'andez and Marc K. Ritter and Matthieu Jeannin and Jheng-Wei Li and Thomas Kloss and Thibaud Louvet and Satoshi Terasaki and Olivier Parcollet and Jan von Delft and Hiroshi Shinaoka and Xavier Waintal},
 date          = {2025},
 title         = {Learning tensor networks with tensor cross interpolation: new algorithms and libraries},
 journal       = {SciPost Phys.},
 volume        = {18},
 pages         = {104},
 doi           = {10.21468/SciPostPhys.18.3.104},
 url           = {https://scipost.org/SciPostPhys.18.3.104},
 file          = {:VonDelft/Fernandez2024.pdf},
 note          = {arXiv:2407.02454 [physics.comp-ph]},
}

@Article{Goreinov1997,
author={Goreinov, S. A.
and Zamarashkin, N. L.
and Tyrtyshnikov, E. E.},
title={Pseudo-skeleton approximations by matrices of maximal volume},
journal={Mathematical Notes},
year={1997},
month={10},
day={01},
volume={62},
number={4},
pages={515-519},
issn={1573-8876},
doi={10.1007/BF02358985},
url={https://doi.org/10.1007/BF02358985}
}

@article{PhysRevX.12.041018,
  title = {Learning Feynman Diagrams with Tensor Trains},
  author = {N\'u\~nez Fern\'andez, Yuriel and Jeannin, Matthieu and Dumitrescu, Philipp T. and Kloss, Thomas and Kaye, Jason and Parcollet, Olivier and Waintal, Xavier},
  journal = {Phys. Rev. X},
  volume = {12},
  issue = {4},
  pages = {041018},
  numpages = {30},
  year = {2022},
  month = {11},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevX.12.041018},
  url = {https://link.aps.org/doi/10.1103/PhysRevX.12.041018}
}

@book{settles2012active,
  title={Active Learning},
  author={Settles, B.},
  isbn={978-3-031-00432-2},
  series={Synthesis lectures on artificial intelligence and machine learning},
  year={2012},
  publisher={Morgan \& Claypool}
}

@article{OSELEDETS201070,
title = {TT-cross approximation for multidimensional arrays},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {1},
pages = {70-88},
year = {2010},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509003747},
author = {Ivan Oseledets and Eugene Tyrtyshnikov},
keywords = {Tensor decompositions, Multi-way arrays, Curse of dimensionality, Interpolation, Multidimensional integration, Cross approximation, Tensor trains, TT decomposition, Singular value decomposition, Low-rank matrices},
abstract = {As is well known, a rank-r matrix can be recovered from a cross of r linearly independent columns and rows, and an arbitrary matrix can be interpolated on the cross entries. Other entries by this cross or pseudo-skeleton approximation are given with errors depending on the closeness of the matrix to a rank-r matrix and as well on the choice of cross. In this paper we extend this construction to d-dimensional arrays (tensors) and suggest a new interpolation formula in which a d-dimensional array is interpolated on the entries of some TT-cross (tensor train-cross). The total number of entries and the complexity of our interpolation algorithm depend on d linearly, so the approach does not suffer from the curse of dimensionality. We also propose a TT-cross method for computation of d-dimensional integrals and apply it to some examples with dimensionality in the range from d=100 up to d=4000 and the relative accuracy of order 10-10. In all constructions we capitalize on the new tensor decomposition in the form of tensor trains (TT-decomposition).}
}

@article{doi:10.1137/090752286,
author = {Oseledets, I. V.},
title = {Tensor-Train Decomposition},
journal = {SIAM Journal on Scientific Computing},
volume = {33},
number = {5},
pages = {2295-2317},
year = {2011},
doi = {10.1137/090752286},

URL = { 
    
        https://doi.org/10.1137/090752286
    
    

},
eprint = { 
    
        https://doi.org/10.1137/090752286
    
    

}
,
    abstract = { A simple nonrecursive form of the tensor decomposition in d dimensions is presented. It does not inherently suffer from the curse of dimensionality, it has asymptotically the same number of parameters as the canonical decomposition, but it is stable and its computation is based on low-rank approximation of auxiliary unfolding matrices. The new form gives a clear and convenient way to implement all basic operations efficiently. A fast rounding procedure is presented, as well as basic linear algebra operations. Examples showing the benefits of the decomposition are given, and the efficiency is demonstrated by the computation of the smallest eigenvalue of a 19-dimensional operator. }
}

@INPROCEEDINGS{6076873,
  author={Savostyanov, Dmitry and Oseledets, Ivan},
  booktitle={The 2011 International Workshop on Multidimensional (nD) Systems}, 
  title={Fast adaptive interpolation of multi-dimensional arrays in tensor train format}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  keywords={Tensile stress;Approximation algorithms;Matrix decomposition;Least squares approximation;Interpolation;Indexes},
  doi={10.1109/nDS.2011.6076873}}

@article{SAVOSTYANOV2014217,
title = {Quasioptimality of maximum-volume cross interpolation of tensors},
journal = {Linear Algebra and its Applications},
volume = {458},
pages = {217-244},
year = {2014},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2014.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0024379514003711},
author = {Dmitry V. Savostyanov},
keywords = {High-dimensional problems, Tensor train format, Maximum-volume principle, Cross interpolation},
abstract = {We consider a cross interpolation of high-dimensional arrays in the tensor train format. We prove that the maximum-volume choice of the interpolation sets provides the quasioptimal interpolation accuracy, that differs from the best possible accuracy by the factor which does not grow exponentially with dimension. For nested interpolation sets we prove the interpolation property and propose greedy cross interpolation algorithms. We justify the theoretical results and measure speed and accuracy of the proposed algorithm with numerical experiments.}
}

@article{DOLGOV2020106869,
title = {Parallel cross interpolation for high-precision calculation of high-dimensional integrals},
journal = {Computer Physics Communications},
volume = {246},
pages = {106869},
year = {2020},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2019.106869},
url = {https://www.sciencedirect.com/science/article/pii/S0010465519302565},
author = {Sergey Dolgov and Dmitry Savostyanov},
keywords = {High-dimensional integration, High precision, Tensor train format, Cross interpolation, Ising integrals, Parallel algorithms},
abstract = {We propose a parallel version of the cross interpolation algorithm and apply it to calculate high-dimensional integrals motivated by Ising model in quantum physics. In contrast to mainstream approaches, such as Monte Carlo and quasi Monte Carlo, the samples calculated by our algorithm are neither random nor form a regular lattice. Instead we calculate the given function along individual dimensions (modes) and use these values to reconstruct its behaviour in the whole domain. The positions of the calculated univariate fibres are chosen adaptively for the given function. The required evaluations can be executed in parallel along each mode (variable) and over all modes. To demonstrate the efficiency of the proposed method, we apply it to compute high-dimensional Ising susceptibility integrals, arising from asymptotic expansions for the spontaneous magnetisation in two-dimensional Ising model of ferromagnetism. We observe strong superlinear convergence of the proposed method, while the MC and qMC algorithms converge sublinearly. Using multiple precision arithmetic, we also observe exponential convergence of the proposed algorithm. Combining high-order convergence, almost perfect scalability up to hundreds of processes, and the same flexibility as MC and qMC, the proposed algorithm can be a new method of choice for problems involving high-dimensional integration, e.g. in statistics, probability, and quantum physics.}
}
@article{SCHNEIDER20101685,
title = {Error estimates for two-dimensional cross approximation},
journal = {Journal of Approximation Theory},
volume = {162},
number = {9},
pages = {1685-1700},
year = {2010},
issn = {0021-9045},
doi = {https://doi.org/10.1016/j.jat.2010.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0021904510000912},
author = {Jan Schneider},
keywords = {Cross approximation, Tensor products, Bilinear forms, Error estimates, Best approximation},
abstract = {In this paper we deal with the approximation of a given function f on [0,1]2 by special bilinear forms ∑i=1kgi⊗hi via the so-called cross approximation. In particular we are interested in estimating the error function f−∑i=1kgi⊗hi of the corresponding algorithm in the maximum norm. There is a large amount of publications available that successfully deal with similar matrix algorithms in applied situations, for example in connection with H-matrices (see Boerm and Grasedyck (2003) [9] or Hackbusch (2007) [16] for many references). But as they do not give satisfactory error estimates, we concentrate on the theoretical issues of the problem in the language of functions. We connect it with related results from other areas of analysis in a historical survey and give a lot of references. Our main result is the connection of the error of our algorithm with the error of best approximation by arbitrary bilinear forms. This will be compared with the different approach in Bebendorf (2008) [6].}
}